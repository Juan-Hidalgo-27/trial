{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Neuro-TabPFN v0.3 - Pipeline\n",
    "\n",
    "**Pipeline completo para predicci贸n causal de outcomes en stroke:**\n",
    "1. Falta actualizar\n",
    "2. \n",
    "3. VAE Adaptativo (cualquier shape)\n",
    "4. TabICL Two-Stage\n",
    "5. Do-Loss Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: H:\\My Drive\\Debbuging Neuro\n"
     ]
    }
   ],
   "source": [
    "# SETUP\n",
    "import os, sys\n",
    "\n",
    "ROOT = \"H:/My Drive/Debbuging Neuro\"\n",
    "DATA_DIR = f\"{ROOT}/Data\"\n",
    "REPO_DIR = f\"{ROOT}/individualized_prescriptive_inference\"\n",
    "RESULTS_DIR = f\"{ROOT}/results_intersynth_full\"\n",
    "REP_DIR = os.path.join(RESULTS_DIR, \"representations\")\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "os.chdir(ROOT)\n",
    "print(f\"Working dir: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elige condici贸n: lesion vs disco, genetics vs receptor, k-fold, threshold\n",
    "lesion_deficit_thresh = \"0.05\"\n",
    "gene_or_receptor = \"receptor\"   # o \"genetics\"\n",
    "kfold = 0\n",
    "input_type = \"lesion\"           # o \"disco\" si tienes disconnectomes\n",
    "\n",
    "stem = f\"{input_type}_{lesion_deficit_thresh}_{gene_or_receptor}_{kfold}\"\n",
    "train_pkl = glob.glob(os.path.join(REP_DIR, stem, f\"train_{input_type}_{lesion_deficit_thresh}_{kfold}.pkl\"))\n",
    "test_pkl  = glob.glob(os.path.join(REP_DIR, stem, f\"test_{input_type}_{lesion_deficit_thresh}_{kfold}.pkl\"))\n",
    "centroids_json = os.path.join(REP_DIR, stem, \"centroids.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install torch torchvision monai nibabel pandas numpy matplotlib scikit-learn datasets \"abagen[io]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonar repo y deps\n",
    "%%capture\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/high-dimensional/individualized_prescriptive_inference.git $REPO_DIR\n",
    "        \n",
    "%cd $REPO_DIR\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, warnings, json\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Tuple, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "from datasets import load_dataset\n",
    "from monai.transforms import Spacing\n",
    "from monai.data import MetaTensor\n",
    "import shutil, glob, json, textwrap, subprocess\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Device: cpu, Shape: (96, 112, 96)\n"
     ]
    }
   ],
   "source": [
    "# CONFIG\n",
    "class Config:\n",
    "    SEED = 42\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    HF_DATASET = \"hugging-science/isles24-stroke\"\n",
    "    N_SUBSET = 500\n",
    "    TARGET_SHAPE = (96, 112, 96)\n",
    "    TARGET_SPACING = (2.0, 2.0, 2.0)\n",
    "    LATENT_DIM = 50\n",
    "    VAE_BASE_CHANNELS = 32\n",
    "    VAE_EPOCHS = 30\n",
    "    VAE_BATCH_SIZE = 16\n",
    "    VAE_LR = 1e-3\n",
    "    VAE_BETA = 1.0\n",
    "    SCM_EFFECT = 5.0\n",
    "    SCM_WEIGHT_Z = 0.5\n",
    "    SCM_WEIGHT_T = 2.0\n",
    "    D_MODEL = 128\n",
    "    N_HEAD = 4\n",
    "    N_LAYERS_COL = 2\n",
    "    N_LAYERS_ROW = 4\n",
    "    DIM_FEEDFORWARD = 512\n",
    "    DROPOUT = 0.1\n",
    "    LR_TABICL = 5e-4\n",
    "    SYN_BATCH = 128\n",
    "    SYN_SEQ = 64\n",
    "    DO_STEPS = 500\n",
    "\n",
    "cfg = Config()\n",
    "random.seed(cfg.SEED); np.random.seed(cfg.SEED); torch.manual_seed(cfg.SEED)\n",
    "print(f\" Device: {cfg.DEVICE}, Shape: {cfg.TARGET_SHAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading ISLES'24...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5926706878e44b4fa2585475b46dbead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30/149...\n",
      "   60/149...\n",
      "   90/149...\n",
      "   120/149...\n",
      " Loaded 149 cases. Shape: (149, 1, 96, 112, 96)\n"
     ]
    }
   ],
   "source": [
    "# Descargar lesiones (4119 m谩scaras MNI)\n",
    "LESIONS_ZIP = f\"{DATA_DIR}/lesions.zip\"\n",
    "if not os.path.exists(LESIONS_ZIP):\n",
    "    !wget -q https://github.com/high-dimensional/individualized_prescriptive_inference/raw/main/lesions.zip -O $LESIONS_ZIP\n",
    "LESIONS_DIR = f\"{DATA_DIR}/lesions_full\"\n",
    "if not os.path.exists(LESIONS_DIR):\n",
    "    !unzip -q $LESIONS_ZIP -d $LESIONS_DIR\n",
    "print(\"Total m谩scaras:\", len(glob.glob(os.path.join(LESIONS_DIR, \"*.nii*\"))))\n",
    "\n",
    "# A帽ade ruta a disconnectomes si los tienes:\n",
    "DISCO_DIR = \"\"  # deja vac铆o si no tienes disconnectomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Ejecutar representaci贸n (embeddings NM/PCA, etc.)\n",
    "#    Se usa por defaults del script (k-folds, latents, nmf/pca ON).\n",
    "rep_cmd = textwrap.dedent(f\"\"\"\n",
    "python software/representation.py \\\n",
    "  --lesionpath {LESIONS_DIR} \\\n",
    "  --discopath \"{DISCO_DIR}\" \\\n",
    "  --savepath {RESULTS_DIR}/representations\n",
    "\"\"\").strip()\n",
    "print(\"Running representation.py ...\")\n",
    "subprocess.run(rep_cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Ground-truth deficit modelling (crea train/test pkl por d茅ficit)\n",
    "#    Usa los atlases del repo (functional_parcellation/2mm_parcellations).\n",
    "\n",
    "def_cmd = textwrap.dedent(f\"\"\"\n",
    "python software/deficit_modelling.py \\\n",
    "  --path {RESULTS_DIR}/representations \\\n",
    "  --lesionpath {LESIONS_DIR} \\\n",
    "  --discopath \"{DISCO_DIR}\" \\\n",
    "  --latent_list 2 4 8 16 32 64 128 256 \\\n",
    "  --kfold_deficits 10 \\\n",
    "  --roi_threshs 0.05 \\\n",
    "  --names genetics receptor \\\n",
    "  --run_ae False \\\n",
    "  --run_vae False \\\n",
    "  --run_nmf True \\\n",
    "  --run_pca True\n",
    "\"\"\").strip()\n",
    "print(\"Running deficit_modelling.py ...\")\n",
    "subprocess.run(def_cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Prescriptive simulations (pipeline completo)\n",
    "#    Usa los defaults amplios: gen茅tica + receptores, lesi贸n + disco (si disco existe),\n",
    "#    m煤ltiples bias/TE/RE, 16 d茅ficits, varios bottlenecks.\n",
    "\n",
    "presc_cmd = textwrap.dedent(f\"\"\"\n",
    "python software/prescription.py \\\n",
    "  --savepath {RESULTS_DIR} \\\n",
    "  --loadpath {RESULTS_DIR}/representations \\\n",
    "  --k 0 1 2 3 4 5 6 7 8 9 \\\n",
    "  --gene_or_receptor genetics receptor \\\n",
    "  --lesion_or_disconnectome lesion {\"disco\" if DISCO_DIR else \"\"} \\\n",
    "  --lesion_deficit_thresh 0.05 0.05 \\\n",
    "  --deficits 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \\\n",
    "  --biasdegree 0 0.25 0.5 0.75 1 \\\n",
    "  --biastype observed unobserved \\\n",
    "  --te 1 0.75 0.5 0.25 \\\n",
    "  --re 0 0.25 0.5 0.75 \\\n",
    "  --bottlenecks 0 2 4 8 16 32 64 128 \\\n",
    "  --simpleatlases False all_territories major_arterial_territories major_arterial_territories_lat major_territories clusters_lat \\\n",
    "  --simpleatlas_argmaxs True \\\n",
    "  --vols True False \\\n",
    "  --centroids False \\\n",
    "  --ml_models logistic_regression extra_trees xgb \\\n",
    "  --use_vae False \\\n",
    "  --use_ae False \\\n",
    "  --use_nmf True \\\n",
    "  --use_pca True\n",
    "\"\"\").strip()\n",
    "print(\"Running prescription.py ... (esto puede tardar MUCHO)\")\n",
    "subprocess.run(presc_cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Listar salidas\n",
    "import pandas as pd, glob, os\n",
    "out_files = glob.glob(os.path.join(RESULTS_DIR, \"prescription\", \"*.pkl\"))\n",
    "print(\"Archivos generados:\", len(out_files))\n",
    "if out_files:\n",
    "    df_sample = pd.read_pickle(out_files[0])\n",
    "    print(df_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_pkl and test_pkl, \"No se encontraron pickles; revisa rutas/flags de representaci贸n.\"\n",
    "train_df = pd.read_pickle(train_pkl[0])\n",
    "test_df  = pd.read_pickle(test_pkl[0])\n",
    "\n",
    "print(\"Cols disponibles:\", train_df.columns[:20], \"... total:\", len(train_df.columns))\n",
    "print(\"Shape train/test:\", train_df.shape, test_df.shape)\n",
    "\n",
    "# Ejemplo: elegir un embedding ya calculado (p.ej. PCA 32D si se activ贸)\n",
    "# Cambia 'pca' por 'nmf'/'vae_means'/'ae' seg煤n lo que activaste\n",
    "bottleneck = 32\n",
    "feat_col = f\"pca_{input_type}_{bottleneck}_K{kfold}\"\n",
    "if feat_col in train_df.columns:\n",
    "    import numpy as np\n",
    "    X_train = np.stack(train_df[feat_col]).astype(\"float32\")\n",
    "    X_test  = np.stack(test_df[feat_col]).astype(\"float32\")\n",
    "else:\n",
    "    raise ValueError(f\"No se encontr贸 la columna {feat_col}; verifica los par谩metros de representaci贸n.\")\n",
    "\n",
    "# Etiquetas de outcome sintetizado (y_true en test) y grupos W en train (asignaci贸n de tratamiento simulada)\n",
    "y_train = train_df[\"y_true\"].to_numpy() if \"y_true\" in train_df else None\n",
    "y_test  = test_df[\"y_true\"].to_numpy()  if \"y_true\" in test_df  else None\n",
    "W_train = train_df[\"group\"].to_numpy() if \"group\" in train_df else None\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", None if y_train is None else y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6 receptor maps\n",
      "Y_intersynth: [0.000, 1.000]\n"
     ]
    }
   ],
   "source": [
    "# INTERSYNTH\n",
    "class MultiReceptorInterSynth:\n",
    "    RECEPTORS = ['D1', 'D2', '5HT1A', '5HT2A', 'GABA', 'mGluR5']\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        self.weight_maps = {r: self._gen_map(r) for r in self.RECEPTORS}\n",
    "        print(f\" {len(self.weight_maps)} receptor maps\")\n",
    "    \n",
    "    def _gen_map(self, receptor):\n",
    "        H, W, D = self.shape\n",
    "        z, y, x = np.linspace(-1,1,H), np.linspace(-1,1,W), np.linspace(-1,1,D)\n",
    "        Z, Y, X = np.meshgrid(z, y, x, indexing='ij')\n",
    "        R = np.sqrt(X**2 + Y**2 + Z**2)\n",
    "        base = np.exp(-3 * (R - 0.7)**2) * (0.5 + 0.5*Y) * (0.5 + 0.5*Z)\n",
    "        if receptor in ['D1', 'D2']:\n",
    "            mod = np.exp(-5*(X**2+Y**2)) * np.exp(-2*(Z+0.3)**2)\n",
    "        elif receptor in ['5HT1A', '5HT2A']:\n",
    "            mod = 0.5 + 0.5*Y\n",
    "        else:\n",
    "            mod = base\n",
    "        result = base * mod\n",
    "        return ((result - result.min()) / (result.max() - result.min() + 1e-8)).astype(np.float32)\n",
    "    \n",
    "    def compute_composite(self, masks, normalize=True):\n",
    "        if masks.ndim == 5: masks = masks[:, 0]\n",
    "        masks = (masks > 0.5).astype(np.float32)\n",
    "        scores = []\n",
    "        for w in self.weight_maps.values():\n",
    "            s = (torch.from_numpy(masks).float() * torch.from_numpy(w).float()).sum(dim=(1,2,3)).numpy()\n",
    "            scores.append(s)\n",
    "        composite = np.mean(scores, axis=0)\n",
    "        if normalize:\n",
    "            composite = (composite - composite.min()) / (composite.max() - composite.min() + 1e-8)\n",
    "        return composite\n",
    "\n",
    "intersynth = MultiReceptorInterSynth(cfg.TARGET_SHAPE)\n",
    "Y_intersynth = intersynth.compute_composite(masks)\n",
    "print(f\"Y_intersynth: [{Y_intersynth.min():.3f}, {Y_intersynth.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch shape: torch.Size([16, 1, 96, 112, 96])\n"
     ]
    }
   ],
   "source": [
    "# DATASET \n",
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, masks_np):\n",
    "        assert masks_np.ndim == 5 and masks_np.shape[1] == 1, \"Expected [N,1,H,W,D]\"\n",
    "        self.m = torch.from_numpy(masks_np).float()\n",
    "    def __len__(self): return len(self.m)\n",
    "    def __getitem__(self, idx): return self.m[idx]\n",
    "\n",
    "dataset = MaskDataset(masks)\n",
    "dataloader = DataLoader(dataset, batch_size=cfg.VAE_BATCH_SIZE, shuffle=True)\n",
    "print(f\" Batch shape: {next(iter(dataloader)).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VAE for (96, 112, 96)\n",
      "   Encoder: (256, 6, 7, 6)=64512\n",
      " VAE: 21,118,245 params\n",
      "\n",
      " Test: torch.Size([2, 1, 96, 112, 96])->torch.Size([2, 1, 96, 112, 96]), loss=945822.7500\n",
      " VAE OK!\n"
     ]
    }
   ],
   "source": [
    "# VAE ADAPTATIVO\n",
    "class ResBlock3D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_ch, out_ch, 3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(out_ch, out_ch, 3, padding=1)\n",
    "        self.bn1, self.bn2 = nn.BatchNorm3d(out_ch), nn.BatchNorm3d(out_ch)\n",
    "        self.skip = nn.Conv3d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        return F.leaky_relu(self.bn2(self.conv2(F.leaky_relu(self.bn1(self.conv1(x)), 0.2))) + self.skip(x), 0.2)\n",
    "\n",
    "class AdaptiveEncoder3D(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dim=64, base_ch=32):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Sequential(nn.Conv3d(1, base_ch, 4, 2, 1), nn.BatchNorm3d(base_ch), nn.LeakyReLU(0.2)),\n",
    "            ResBlock3D(base_ch, base_ch),\n",
    "            nn.Sequential(nn.Conv3d(base_ch, base_ch*2, 4, 2, 1), nn.BatchNorm3d(base_ch*2), nn.LeakyReLU(0.2)),\n",
    "            ResBlock3D(base_ch*2, base_ch*2),\n",
    "            nn.Sequential(nn.Conv3d(base_ch*2, base_ch*4, 4, 2, 1), nn.BatchNorm3d(base_ch*4), nn.LeakyReLU(0.2)),\n",
    "            ResBlock3D(base_ch*4, base_ch*4),\n",
    "            nn.Sequential(nn.Conv3d(base_ch*4, base_ch*8, 4, 2, 1), nn.BatchNorm3d(base_ch*8), nn.LeakyReLU(0.2)),\n",
    "            ResBlock3D(base_ch*8, base_ch*8),\n",
    "        ])\n",
    "        self.feature_size, self.feature_shape = self._get_size()\n",
    "        self.fc_mu = nn.Linear(self.feature_size, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.feature_size, latent_dim)\n",
    "        print(f\"   Encoder: {self.feature_shape}={self.feature_size}\")\n",
    "    \n",
    "    def _get_size(self):\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, 1, *self.input_shape)\n",
    "            for b in self.blocks: x = b(x)\n",
    "            return x.numel(), tuple(x.shape[1:])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for b in self.blocks: x = b(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc_mu(x), self.fc_logvar(x)\n",
    "\n",
    "class AdaptiveDecoder3D(nn.Module):\n",
    "    def __init__(self, latent_dim, feature_shape, output_shape, base_ch=32):\n",
    "        super().__init__()\n",
    "        self.feature_shape, self.output_shape = feature_shape, output_shape\n",
    "        self.fc = nn.Linear(latent_dim, int(np.prod(feature_shape)))\n",
    "        ch = base_ch * 8\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Sequential(nn.ConvTranspose3d(ch, ch//2, 4, 2, 1), nn.BatchNorm3d(ch//2), nn.ReLU()),\n",
    "            ResBlock3D(ch//2, ch//2),\n",
    "            nn.Sequential(nn.ConvTranspose3d(ch//2, ch//4, 4, 2, 1), nn.BatchNorm3d(ch//4), nn.ReLU()),\n",
    "            ResBlock3D(ch//4, ch//4),\n",
    "            nn.Sequential(nn.ConvTranspose3d(ch//4, ch//8, 4, 2, 1), nn.BatchNorm3d(ch//8), nn.ReLU()),\n",
    "            ResBlock3D(ch//8, ch//8),\n",
    "            nn.Sequential(nn.ConvTranspose3d(ch//8, 1, 4, 2, 1), nn.Sigmoid())\n",
    "        ])\n",
    "        self._out = self._get_out()\n",
    "        self.needs_resize = self._out != output_shape\n",
    "    \n",
    "    def _get_out(self):\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, *self.feature_shape)\n",
    "            for b in self.blocks: x = b(x)\n",
    "            return tuple(x.shape[2:])\n",
    "    \n",
    "    def forward(self, z):\n",
    "        x = self.fc(z).view(-1, *self.feature_shape)\n",
    "        for b in self.blocks: x = b(x)\n",
    "        if self.needs_resize: x = F.interpolate(x, size=self.output_shape, mode='trilinear', align_corners=False)\n",
    "        return x\n",
    "\n",
    "class AdaptiveVAE3D(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dim=64, base_ch=32):\n",
    "        super().__init__()\n",
    "        print(f\" VAE for {input_shape}\")\n",
    "        self.encoder = AdaptiveEncoder3D(input_shape, latent_dim, base_ch)\n",
    "        self.decoder = AdaptiveDecoder3D(latent_dim, self.encoder.feature_shape, input_shape, base_ch)\n",
    "        print(f\" VAE: {sum(p.numel() for p in self.parameters()):,} params\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = mu + torch.randn_like(mu) * torch.exp(0.5 * logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "    \n",
    "    def encode(self, x): return self.encoder(x)[0]\n",
    "\n",
    "def vae_loss(recon, original, mu, logvar, beta=1.0):\n",
    "    # CRITICAL: verify shapes match\n",
    "    assert recon.shape == original.shape, f\"Shape mismatch: {recon.shape} vs {original.shape}\"\n",
    "    bs = original.size(0)\n",
    "    recon_l = F.binary_cross_entropy(recon, original, reduction='sum') / bs\n",
    "    kl_l = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / bs\n",
    "    return recon_l + beta * kl_l, recon_l, kl_l\n",
    "\n",
    "vae = AdaptiveVAE3D(cfg.TARGET_SHAPE, cfg.LATENT_DIM, cfg.VAE_BASE_CHANNELS).to(cfg.DEVICE)\n",
    "with torch.no_grad():\n",
    "    test = next(iter(dataloader))[:2].to(cfg.DEVICE)\n",
    "    recon, mu, logvar = vae(test)\n",
    "    loss, _, _ = vae_loss(recon, test, mu, logvar)\n",
    "    print(f\"\\n Test: {test.shape}->{recon.shape}, loss={loss.item():.4f}\")\n",
    "print(\" VAE OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training VAE 30 epochs...\n",
      "   Ep 10: Loss=22485.3082, Dice=0.1311\n"
     ]
    }
   ],
   "source": [
    "# TRAIN VAE\n",
    "def train_vae(vae, dl, epochs=cfg.VAE_EPOCHS):\n",
    "    opt = optim.Adam(vae.parameters(), lr=cfg.VAE_LR)\n",
    "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.5, patience=5)\n",
    "    history = {'loss': [], 'dice': []}\n",
    "    vae.train()\n",
    "    print(f\"\\n Training VAE {epochs} epochs...\")\n",
    "    for ep in range(epochs):\n",
    "        total_l, total_d, n = 0, 0, 0\n",
    "        for batch in dl:\n",
    "            batch = batch.to(cfg.DEVICE)\n",
    "            opt.zero_grad()\n",
    "            recon, mu, logvar = vae(batch)\n",
    "            loss, _, _ = vae_loss(recon, batch, mu, logvar, cfg.VAE_BETA)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(vae.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            total_l += loss.item()\n",
    "            p, t = (recon > 0.5).float(), (batch > 0.5).float()\n",
    "            total_d += (2.0 * (p * t).sum() / (p.sum() + t.sum() + 1e-8)).item()\n",
    "            n += 1\n",
    "        history['loss'].append(total_l/n)\n",
    "        history['dice'].append(total_d/n)\n",
    "        sched.step(total_l/n)\n",
    "        if (ep+1) % 10 == 0: print(f\"   Ep {ep+1}: Loss={total_l/n:.4f}, Dice={total_d/n:.4f}\")\n",
    "    print(f\" Final Dice: {history['dice'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "vae_history = train_vae(vae, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT LATENTS\n",
    "@torch.no_grad()\n",
    "def extract_latents(vae, dl):\n",
    "    vae.eval()\n",
    "    return np.concatenate([vae.encode(b.to(cfg.DEVICE)).cpu().numpy() for b in dl])\n",
    "\n",
    "Z = extract_latents(vae, dataloader)\n",
    "print(f\" Z: {Z.shape}, mean={Z.mean():.4f}, std={Z.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABICL TWO-STAGE\n",
    "class LearnablePE(nn.Module):\n",
    "    def __init__(self, d, max_len=512, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.pe = nn.Parameter(torch.randn(1, max_len, d) * 0.02)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "    def forward(self, x): return self.drop(x + self.pe[:, :x.size(1), :])\n",
    "\n",
    "class FeatureEmbed(nn.Module):\n",
    "    def __init__(self, d, n_feat, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.n_feat = n_feat\n",
    "        self.proj = nn.Linear(1, d)\n",
    "        self.feat_emb = nn.Parameter(torch.randn(1, n_feat, 1, d) * 0.02)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "    def forward(self, x):\n",
    "        B, S, F = x.shape\n",
    "        x = x.permute(0, 2, 1).unsqueeze(-1)\n",
    "        x = self.proj(x) + self.feat_emb\n",
    "        return self.drop(x.view(B * F, S, -1))\n",
    "\n",
    "class ColBlock(nn.Module):\n",
    "    def __init__(self, d, nh, ff, drop):\n",
    "        super().__init__()\n",
    "        layer = nn.TransformerEncoderLayer(d, nh, ff, drop, batch_first=True, activation='gelu', norm_first=True)\n",
    "        self.enc = nn.TransformerEncoder(layer, 1)\n",
    "    def forward(self, x): return self.enc(x)\n",
    "\n",
    "class RowBlock(nn.Module):\n",
    "    def __init__(self, d, n_feat, nh, nl, ff, drop):\n",
    "        super().__init__()\n",
    "        self.n_feat, self.d = n_feat, d\n",
    "        rd = d * n_feat\n",
    "        self.pe = LearnablePE(rd, drop=drop)\n",
    "        layer = nn.TransformerEncoderLayer(rd, nh, ff, drop, batch_first=True, activation='gelu', norm_first=True)\n",
    "        self.enc = nn.TransformerEncoder(layer, nl)\n",
    "    def forward(self, h):\n",
    "        B, S, F, D = h.shape\n",
    "        return self.enc(self.pe(h.view(B, S, F * D)))\n",
    "\n",
    "class TabICLTwoStage(nn.Module):\n",
    "    def __init__(self, n_feat, d=128, nh_c=4, nh_r=4, nl_c=2, nl_r=4, ff=512, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.n_feat, self.d = n_feat, d\n",
    "        self.embed = FeatureEmbed(d, n_feat, drop)\n",
    "        self.col_blks = nn.ModuleList([ColBlock(d, nh_c, ff, drop) for _ in range(nl_c)])\n",
    "        self.row_blk = RowBlock(d, n_feat, nh_r, nl_r, ff*2, drop)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d * n_feat),\n",
    "            nn.Linear(d * n_feat, d), nn.GELU(), nn.Dropout(drop),\n",
    "            nn.Linear(d, 1)\n",
    "        )\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
    "        print(f\" TabICL: {sum(p.numel() for p in self.parameters()):,} params\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, S, F = x.shape\n",
    "        h = self.embed(x)\n",
    "        for blk in self.col_blks: h = blk(h)\n",
    "        h = h.view(B, F, S, self.d).permute(0, 2, 1, 3).contiguous()\n",
    "        return self.head(self.row_blk(h))\n",
    "\n",
    "n_feat = cfg.LATENT_DIM + 2\n",
    "model = TabICLTwoStage(n_feat, cfg.D_MODEL, cfg.N_HEAD, cfg.N_HEAD, cfg.N_LAYERS_COL, cfg.N_LAYERS_ROW, cfg.DIM_FEEDFORWARD, cfg.DROPOUT).to(cfg.DEVICE)\n",
    "with torch.no_grad():\n",
    "    tx = torch.randn(2, 10, n_feat).to(cfg.DEVICE)\n",
    "    print(f\" {tx.shape}->{model(tx).shape}\")\n",
    "print(\" TabICL OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO-LOSS TRAINING\n",
    "def make_batch(bs=cfg.SYN_BATCH, sl=cfg.SYN_SEQ, nf=cfg.LATENT_DIM, real_Z=None):\n",
    "    if real_Z is None:\n",
    "        z = torch.randn(bs, sl, nf, device=cfg.DEVICE)\n",
    "    else:\n",
    "        idx = torch.randint(0, real_Z.shape[0], (bs*sl,), device=cfg.DEVICE)\n",
    "        z = real_Z[idx].view(bs, sl, -1)\n",
    "        if z.shape[-1] < nf: z = torch.cat([z, torch.zeros(bs, sl, nf - z.shape[-1], device=cfg.DEVICE)], -1)\n",
    "        elif z.shape[-1] > nf: z = z[:, :, :nf]\n",
    "    logits = cfg.SCM_WEIGHT_T * z[:,:,0] + torch.randn_like(z[:,:,0])\n",
    "    t = torch.bernoulli(torch.sigmoid(logits)).unsqueeze(-1)\n",
    "    y = cfg.SCM_EFFECT * t - cfg.SCM_WEIGHT_Z * z[:,:,0:1] + 0.1 * torch.randn_like(t)\n",
    "    return z, t, y\n",
    "\n",
    "def do_step(model, opt, loss_fn, z, t, y):\n",
    "    model.train()\n",
    "    Zc, Zq = z[:,:-1,:], z[:,-1:,:]\n",
    "    Tc, Tq = t[:,:-1,:], torch.bernoulli(torch.full_like(t[:,-1:,:], 0.5))\n",
    "    Yc = y[:,:-1,:]\n",
    "    Yq_true = cfg.SCM_EFFECT * Tq - cfg.SCM_WEIGHT_Z * Zq[:,:,0:1]\n",
    "    \n",
    "    # CRITICAL: concatenate features, not separate args\n",
    "    x = torch.cat([torch.cat([Zc, Zq], 1), torch.cat([Tc, Tq], 1), torch.cat([Yc, torch.zeros_like(Yq_true)], 1)], -1)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss = loss_fn(model(x)[:,-1:,:], Yq_true)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    opt.step()\n",
    "    return loss.item()\n",
    "\n",
    "def train_causal(model, steps=cfg.DO_STEPS, real_Z=None):\n",
    "    opt = optim.AdamW(model.parameters(), lr=cfg.LR_TABICL, weight_decay=0.01)\n",
    "    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=steps)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    Zt = torch.from_numpy(real_Z).float().to(cfg.DEVICE) if real_Z is not None else None\n",
    "    losses = []\n",
    "    print(f\"\\n Training {steps} steps...\")\n",
    "    for s in range(steps):\n",
    "        z, t, y = make_batch(real_Z=Zt if s % 2 == 0 else None)\n",
    "        losses.append(do_step(model, opt, loss_fn, z, t, y))\n",
    "        sched.step()\n",
    "        if (s+1) % 100 == 0: print(f\"   Step {s+1}: Loss={np.mean(losses[-100:]):.4f}\")\n",
    "    print(f\" Final: {np.mean(losses[-50:]):.4f}\")\n",
    "    return losses\n",
    "\n",
    "loss_hist = train_causal(model, cfg.DO_STEPS, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "@torch.no_grad()\n",
    "def compute_pehe(model, n=20):\n",
    "    model.eval()\n",
    "    errs = []\n",
    "    for _ in range(n):\n",
    "        z, t, y = make_batch()\n",
    "        zn = torch.randn_like(z[:,:1,:])\n",
    "        Zi = torch.cat([z, zn], 1)\n",
    "        T1 = torch.cat([t, torch.ones_like(t[:,:1,:])], 1)\n",
    "        T0 = torch.cat([t, torch.zeros_like(t[:,:1,:])], 1)\n",
    "        Yi = torch.cat([y, torch.zeros_like(y[:,:1,:])], 1)\n",
    "        y1 = model(torch.cat([Zi, T1, Yi], -1))[:,-1,0]\n",
    "        y0 = model(torch.cat([Zi, T0, Yi], -1))[:,-1,0]\n",
    "        errs.append(((y1 - y0 - cfg.SCM_EFFECT)**2).mean().sqrt().item())\n",
    "    return np.mean(errs)\n",
    "\n",
    "@torch.no_grad()\n",
    "def cate_real(model, Zr, bs=16):\n",
    "    model.eval()\n",
    "    Zt = torch.from_numpy(Zr).float().to(cfg.DEVICE)\n",
    "    cates = []\n",
    "    for i in range(0, len(Zt), bs):\n",
    "        zb = Zt[i:i+bs]\n",
    "        B, F = zb.shape\n",
    "        zc = torch.randn(B, 5, F, device=cfg.DEVICE)\n",
    "        logits = cfg.SCM_WEIGHT_T * zc[:,:,0] + torch.randn_like(zc[:,:,0])\n",
    "        tc = torch.bernoulli(torch.sigmoid(logits)).unsqueeze(-1)\n",
    "        yc = cfg.SCM_EFFECT * tc - cfg.SCM_WEIGHT_Z * zc[:,:,0:1]\n",
    "        zq = zb.unsqueeze(1)\n",
    "        def pred(tv):\n",
    "            Zi = torch.cat([zc, zq], 1)\n",
    "            Ti = torch.cat([tc, torch.full((B,1,1), tv, device=cfg.DEVICE)], 1)\n",
    "            Yi = torch.cat([yc, torch.zeros(B,1,1, device=cfg.DEVICE)], 1)\n",
    "            return model(torch.cat([Zi, Ti, Yi], -1))[:,-1,0]\n",
    "        cates.append((pred(1.0) - pred(0.0)).cpu())\n",
    "    return torch.cat(cates).numpy()\n",
    "\n",
    "pehe = compute_pehe(model, 50)\n",
    "cate = cate_real(model, Z)\n",
    "print(f\"\\n RESULTS:\")\n",
    "print(f\"   PEHE: {pehe:.4f}\")\n",
    "print(f\"   CATE: mean={cate.mean():.3f}, std={cate.std():.3f}\")\n",
    "print(f\"   True : {cfg.SCM_EFFECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTS\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "ax[0].plot(loss_hist, alpha=0.3)\n",
    "ma = np.convolve(loss_hist, np.ones(20)/20, mode='valid')\n",
    "ax[0].plot(range(19, len(loss_hist)), ma, 'r-', lw=2)\n",
    "ax[0].set_xlabel('Step'); ax[0].set_ylabel('Loss'); ax[0].set_title('Do-Loss')\n",
    "\n",
    "ax[1].hist(cate, bins=25, alpha=0.7, edgecolor='k')\n",
    "ax[1].axvline(cate.mean(), color='r', ls='--', lw=2, label=f'Mean: {cate.mean():.2f}')\n",
    "ax[1].axvline(cfg.SCM_EFFECT, color='g', ls=':', lw=2, label=f'True: {cfg.SCM_EFFECT}')\n",
    "ax[1].legend(); ax[1].set_xlabel('CATE'); ax[1].set_title('CATE Distribution')\n",
    "\n",
    "ax[2].scatter(Y_intersynth, cate, alpha=0.5, edgecolors='k')\n",
    "ax[2].set_xlabel('InterSynth'); ax[2].set_ylabel('CATE'); ax[2].set_title('CATE vs Anatomy')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SAVE\n",
    "os.makedirs(\"Data/checkpoints\", exist_ok=True)\n",
    "np.save(\"Data/latents.npy\", Z)\n",
    "np.save(\"Data/intersynth.npy\", Y_intersynth)\n",
    "np.save(\"Data/cate.npy\", cate)\n",
    "torch.save({'state_dict': vae.state_dict(), 'history': vae_history}, \"Data/checkpoints/vae.pt\")\n",
    "torch.save({'state_dict': model.state_dict(), 'losses': loss_hist}, \"Data/checkpoints/tabicl.pt\")\n",
    "with open(\"Data/metrics.json\", 'w') as f:\n",
    "    json.dump({'pehe': pehe, 'cate_mean': float(cate.mean()), 'cate_std': float(cate.std()), 'true_tau': cfg.SCM_EFFECT}, f, indent=2)\n",
    "print(\"\\n Saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-debugging]",
   "language": "python",
   "name": "conda-env-anaconda3-debugging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
